{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8afdb95",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff285fb-c13d-45a6-a133-8fc47e3c1d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c539b4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Dataset\n",
    "animes = pd.read_csv(\"data/animes.csv\", encoding=\"ISO-8859-1\")\n",
    "animes.head() #display in table\n",
    "\n",
    "# print(animes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df3bff",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c11e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for checking is there any null value\n",
    "print(\"Total null value in dataset:\")\n",
    "print(animes.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50929f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning null value\n",
    "animes['synopsis'] = animes['synopsis'].fillna(\"\")\n",
    "animes['genre'] = animes['genre'].fillna(\"\")\n",
    "\n",
    "#for checking is there still have any null value\n",
    "print(\"\\nTotal null value in dataset (specific column):\")\n",
    "print(animes[['uid','title','synopsis', 'genre']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only useful columns\n",
    "animes = animes[['uid', 'title', 'synopsis', 'genre']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f2ff5",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cacbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Combine synopsis + genres into one content field\n",
    "animes['content'] = animes['synopsis'] + \" \" + animes['genre'].apply(lambda x: \" \".join(eval(x)) if isinstance(x, str) else \"\")\n",
    "\n",
    "#Remove all english stop words such as 'the', 'a'\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(animes['content'])\n",
    "print(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ff800",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70efec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_by_query(query, top_n=20):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sim_scores = cosine_similarity(query_vec, tfidf_matrix).ravel()\n",
    "    top_indices = sim_scores.argsort()[-top_n:][::-1]\n",
    "    return animes['title'].iloc[top_indices].tolist()\n",
    "\n",
    "# Example\n",
    "print(recommend_by_query(\"comedy and school\"))\n",
    "print(recommend_by_query(\"Is there any sports high school anime recommended?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d262eb",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- Data Cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f87a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Loading Dataset\n",
    "animes = pd.read_csv(\"data/animes.csv\", encoding=\"ISO-8859-1\")\n",
    "animes.head() #display in table\n",
    "\n",
    "#for checking is there any null value\n",
    "print(\"Total null value in dataset:\")\n",
    "print(animes.isnull().sum())\n",
    "\n",
    "#cleaning null value\n",
    "animes['synopsis'] = animes['synopsis'].fillna(\"\")\n",
    "animes['genre'] = animes['genre'].fillna(\"\")\n",
    "\n",
    "#for checking is there still have any null value\n",
    "print(\"\\nTotal null value in dataset (specific column):\")\n",
    "print(animes[['uid','title','synopsis', 'genre']].isnull().sum())\n",
    "\n",
    "# Keep only useful columns\n",
    "animes = animes[['uid', 'title', 'synopsis', 'genre']]\n",
    "\n",
    "# Combine synopsis + genres into one content field\n",
    "animes['content'] = animes['synopsis'] + \" \" + animes['genre'].apply(lambda x: \" \".join(eval(x)) if isinstance(x, str) else \"\")\n",
    "\n",
    "\n",
    "def recommend_by_query(query, top_n=20):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sim_scores = cosine_similarity(query_vec, tfidf_matrix).ravel()\n",
    "    top_indices = sim_scores.argsort()[-top_n:][::-1]\n",
    "    return animes['title'].iloc[top_indices].tolist()\n",
    "\n",
    "# Example\n",
    "print(recommend_by_query(\"comedy and school\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1998053d",
   "metadata": {},
   "source": [
    "## NLP Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55472b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all english stop words such as 'the', 'a'\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(animes['content'])\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb5493",
   "metadata": {},
   "source": [
    "## Function\n",
    "- Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_by_query(query, top_n=20):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sim_scores = cosine_similarity(query_vec, tfidf_matrix).ravel()\n",
    "    top_indices = sim_scores.argsort()[-top_n:][::-1]\n",
    "    return animes['title'].iloc[top_indices].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8637030",
   "metadata": {},
   "source": [
    "## Sample Test\n",
    "- Test Run Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2865b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "print(recommend_by_query(\"comedy and school\")) \n",
    "print(recommend_by_query(\"Is there any sports high school anime recommended?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
